{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":860,"status":"ok","timestamp":1739296844382,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"},"user_tz":-60},"id":"IIMqcJCihkJ6"},"outputs":[],"source":["from transformers import BertTokenizer, BertModel, AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n","model = BertModel.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4465,"status":"ok","timestamp":1739297127682,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"},"user_tz":-60},"id":"Ct6g42yeX3Z0","outputId":"c9bae82f-bd44-4608-9f3e-0d8dc32c6e5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'nlu-benchmark'...\n","remote: Enumerating objects: 400, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 400 (delta 2), reused 11 (delta 2), pack-reused 389 (from 1)\u001b[K\n","Receiving objects: 100% (400/400), 1.19 MiB | 1.33 MiB/s, done.\n","Resolving deltas: 100% (248/248), done.\n"]}],"source":["!pip install -q datasets\n","!git clone https://github.com/sonos/nlu-benchmark.git\n","# !pip install -q torch"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uzlH2PTYfif3","executionInfo":{"status":"ok","timestamp":1739297129381,"user_tz":-60,"elapsed":181,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["import json\n","from datasets import Dataset\n","\n","final_data = []\n","intent_list = []\n","intentpath_list = [\n","    \"/content/nlu-benchmark/2017-06-custom-intent-engines/PlayMusic/train_PlayMusic_full.json\",\n","    \"/content/nlu-benchmark/2017-06-custom-intent-engines/AddToPlaylist/train_AddToPlaylist_full.json\",\n","    \"/content/nlu-benchmark/2017-06-custom-intent-engines/BookRestaurant/train_BookRestaurant_full.json\",\n","    \"/content/nlu-benchmark/2017-06-custom-intent-engines/GetWeather/train_GetWeather_full.json\",\n","    \"/content/nlu-benchmark/2017-06-custom-intent-engines/RateBook/train_RateBook_full.json\",\n","    \"/content/nlu-benchmark/2017-06-custom-intent-engines/SearchCreativeWork/train_SearchCreativeWork_full.json\",\n","    \"/content/nlu-benchmark/2017-06-custom-intent-engines/SearchScreeningEvent/train_SearchScreeningEvent_full.json\"\n","]\n","\n","for path in intentpath_list:\n","    with open(path, \"r\", encoding=\"latin-1\") as f:\n","        data = json.load(f)\n","\n","    intent_name = (list(data.keys())[0])\n","    data = data[intent_name]\n","    for i in data:\n","        i['intent'] = intent_name\n","    final_data.extend(data)\n","data = Dataset.from_list(final_data)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1739297130865,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"},"user_tz":-60},"id":"dQWGAoJxmbFL","outputId":"cff43c2b-4475-456a-b506-7cae0734b588"},"outputs":[{"output_type":"stream","name":"stdout","text":["BookRestaurant\n","PlayMusic\n","BookRestaurant\n","BookRestaurant\n","BookRestaurant\n","SearchScreeningEvent\n","RateBook\n","GetWeather\n","RateBook\n","SearchCreativeWork\n"]}],"source":["data = data.shuffle()\n","for i in range(10):\n","    print(data[i]['intent'])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"IsohD2JzjreB","executionInfo":{"status":"ok","timestamp":1739297132724,"user_tz":-60,"elapsed":1748,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["entity_set = set()\n","for idx in range(len(data)):\n","    for j in data[idx]['data']:\n","        slot_I = \"I-\" + str(j['entity'])\n","        entity_set.add(slot_I)\n","        slot_B = \"B-\" + str(j['entity'])\n","        entity_set.add(slot_B)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"PG9PjQ7akiCQ","executionInfo":{"status":"ok","timestamp":1739297134140,"user_tz":-60,"elapsed":1405,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["intent_set = set()\n","for idx in range(len(data)):\n","    intent_set.add(data[idx]['intent'])"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"e_YuXDaAj-bF","executionInfo":{"status":"ok","timestamp":1739297134208,"user_tz":-60,"elapsed":24,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["entity_to_idx = {}\n","idx_to_entity = {}\n","for idx, ent in enumerate(entity_set):\n","    entity_to_idx[ent] = idx\n","    idx_to_entity[idx] = ent\n","entity_to_idx['O'] = 80\n","entity_to_idx[tokenizer.pad_token] = -100\n","idx_to_entity[-100] = tokenizer.pad_token\n","idx_to_entity[80] = 'O'"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1739297134232,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"},"user_tz":-60},"id":"df1TTo_KQO0u","outputId":"99d25038-6ec9-4cec-eea8-03732ba0cd0e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["82"]},"metadata":{},"execution_count":14}],"source":["len(entity_to_idx)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"KxH6tNu4mdj2","executionInfo":{"status":"ok","timestamp":1739297134264,"user_tz":-60,"elapsed":31,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["intent_to_idx = {}\n","idx_to_intent = {}\n","for idx, intent in enumerate(intent_set):\n","    intent_to_idx[intent] = idx\n","    idx_to_intent[idx] = intent"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"84ot57LP9rGM","executionInfo":{"status":"ok","timestamp":1739297137608,"user_tz":-60,"elapsed":17,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset as torchDataset\n","from torch.utils.data import DataLoader\n","\n","import torch\n","from torch.utils.data import Dataset as torchDataset\n","from torch.utils.data import DataLoader\n","\n","class SnipsDataset(torchDataset):\n","    \"\"\"\n","    Dataset for SNIPS NLU task.\n","    \"\"\"\n","    def __init__(self, data, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.data = data\n","\n","    def __getitem__(self, idx):\n","        sentence_tokens, slots_list = self.sample_example(idx)\n","\n","        inputs = self.tokenizer(\n","            sentence_tokens,\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=50,\n","            return_tensors=\"pt\",\n","            is_split_into_words=True\n","        )\n","\n","        word_ids = inputs.word_ids()\n","        aligned_slots = []\n","        prev_word_id = None\n","\n","        for word_id in word_ids:\n","            if word_id is None:\n","                aligned_slots.append(-100)\n","            elif word_id != prev_word_id:\n","                aligned_slots.append(slots_list[word_id])\n","            else:\n","                base_slot = slots_list[word_id]\n","                if base_slot != entity_to_idx[\"O\"]:\n","                    entity_name = list(entity_to_idx.keys())[list(entity_to_idx.values()).index(base_slot)][2:]\n","                    aligned_slots.append(entity_to_idx[\"I-\" + entity_name])\n","                else:\n","                    aligned_slots.append(base_slot)\n","            prev_word_id = word_id\n","\n","        assert len(aligned_slots) == inputs[\"input_ids\"].shape[1], \"Slots and tokens length mismatch\"\n","\n","        return {\n","            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n","            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n","            \"slots\": torch.tensor(aligned_slots, dtype=torch.long),\n","            \"intent\": torch.tensor(intent_to_idx[self.data[idx][\"intent\"]], dtype=torch.long)\n","        }\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def sample_example(self, idx):\n","        instance = self.data[idx]\n","        sentence_tokens = []\n","        slot_labels = []\n","\n","        for word_info in instance['data']:\n","            word_text = word_info['text']\n","            word_tokens = self.tokenizer.tokenize(word_text)\n","            sentence_tokens.extend(word_tokens)\n","\n","            if 'entity' in word_info and word_info['entity']:\n","                entity = word_info['entity']\n","                slot_list = [f\"I-{entity}\"] * len(word_tokens)\n","                slot_list[0] = f\"B-{entity}\"\n","            else:\n","                slot_list = [\"O\"] * len(word_tokens)\n","\n","            slot_labels.extend(slot_list)\n","\n","        sentence_tokens = [\"[CLS]\"] + sentence_tokens + [\"[SEP]\"]\n","        slot_labels = [\"O\"] + slot_labels + [\"O\"]\n","\n","        assert len(sentence_tokens) == len(slot_labels), \"Tokens and slots length mismatch!\"\n","\n","        return sentence_tokens, [entity_to_idx[slot] for slot in slot_labels]"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"wXpyeuc0El9K","executionInfo":{"status":"ok","timestamp":1739297445646,"user_tz":-60,"elapsed":22,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["import torch\n","\n","def custom_collate_fn(batch):\n","    input_ids = [item['input_ids'] for item in batch]\n","    attention_masks = [item['attention_mask'] for item in batch]\n","    slot_labels = [item['slots'] for item in batch]\n","    intent_labels = [item['intent'] for item in batch]\n","\n","    max_len = max(len(x) for x in input_ids)\n","\n","    def pad_sequence(seq, pad_value):\n","        return seq + [pad_value] * (max_len - len(seq))\n","\n","    pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n","    input_ids = [pad_sequence(x.tolist(), pad_token_id) for x in input_ids]\n","\n","    attention_masks = [pad_sequence(x.tolist(), 0) for x in attention_masks]\n","\n","    slot_labels = [pad_sequence(x.tolist(), -100) for x in slot_labels]\n","\n","    input_ids = torch.tensor(input_ids, dtype=torch.long)\n","    attention_masks = torch.tensor(attention_masks, dtype=torch.long)\n","    slot_labels = torch.tensor(slot_labels, dtype=torch.long)\n","    intent_labels = torch.tensor(intent_labels, dtype=torch.long)\n","\n","    return {\n","        'input_ids': input_ids,\n","        'attention_mask': attention_masks,\n","        'slots': slot_labels,\n","        'intent': intent_labels\n","    }"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"H0fQfKM8jz3F","executionInfo":{"status":"ok","timestamp":1739297447819,"user_tz":-60,"elapsed":15,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["import torch\n","from transformers import BertModel\n","\n","class JointBert(torch.nn.Module):\n","    def __init__(self, num_intent, num_slots,  bert_model=None):\n","        super(JointBert, self).__init__()\n","        if bert_model is None:\n","            self.model = BertModel.from_pretrained(\"bert-base-uncased\")\n","        else:\n","            self.model = bert_model\n","        self.num_slots = num_slots\n","        self.num_intent = num_intent\n","\n","        self.dropout = torch.nn.Dropout(0.2)\n","        self.intent_classifier = torch.nn.Linear(768, num_intent)\n","        self.slot_classifier = torch.nn.Linear(768, num_slots)\n","\n","    def forward(self, input_ids, attention_mask, slot_labels=None, intent_labels=None):\n","        outputs = self.model(input_ids, attention_mask=attention_mask)\n","        hidden_states = outputs.last_hidden_state  # (batch, seq_length, 768)\n","        hidden_states = self.dropout(hidden_states)\n","        # Intent Classification\n","        intent_logits = self.intent_classifier(hidden_states[:, 0, :])  # (batch, num_intents)\n","\n","        # Slots Classification\n","        slot_logits = self.slot_classifier(hidden_states)  # (batch, seq_length, num_slots)\n","\n","        if slot_labels is not None and intent_labels is not None:\n","            loss_fn_slots = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","            loss_slot = loss_fn_slots(slot_logits.view(-1, self.num_slots), slot_labels.view(-1))\n","\n","            loss_fn_intent = torch.nn.CrossEntropyLoss()\n","            loss_intent = loss_fn_intent(intent_logits, intent_labels)\n","\n","            total_loss = loss_slot + loss_intent\n","\n","            return total_loss, intent_logits, slot_logits\n","        else:\n","            slot_preds = torch.argmax(slot_logits, dim=-1)\n","            intent_preds = torch.argmax(intent_logits, dim=-1)\n","            return intent_preds, slot_preds\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"jxiIg-10W6h6","executionInfo":{"status":"ok","timestamp":1739297455569,"user_tz":-60,"elapsed":25,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","import random\n","\n","random.seed(42)\n","random.shuffle(final_data)\n","\n","train_data, val_data = train_test_split(final_data, test_size=0.2, random_state=42)\n","\n","batch_size = 128\n","\n","train_dataloader = DataLoader(SnipsDataset(train_data, tokenizer), batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True)\n","val_dataloader = DataLoader(SnipsDataset(val_data, tokenizer), batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60,"status":"ok","timestamp":1739297449184,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"},"user_tz":-60},"id":"3hu4hiZqXs4l","outputId":"072e214d-724d-4443-b744-dbdd4117bfe1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 50])"]},"metadata":{},"execution_count":29}],"source":["next(iter(train_dataloader))['input_ids'].shape"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"6MG_tsziJATz","executionInfo":{"status":"ok","timestamp":1739297647184,"user_tz":-60,"elapsed":531,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["jb = JointBert(num_intent=len(intent_to_idx), num_slots=len(entity_to_idx))"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"D6NihQi2JXYW","executionInfo":{"status":"ok","timestamp":1739298973814,"user_tz":-60,"elapsed":468874,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}},"outputId":"7c4bfd5a-d2e6-454e-d5ff-028eb901629e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 finished | Avg Train Loss: 1.6140\n","ðŸ”¹ Validation | Loss: 0.2326 | Intent Acc: 0.9888 | Slot Acc: 0.9705\n","Epoch 1 finished | Avg Train Loss: 1.4758\n","ðŸ”¹ Validation | Loss: 0.2425 | Intent Acc: 0.9898 | Slot Acc: 0.9707\n","Epoch 2 finished | Avg Train Loss: 1.5539\n","ðŸ”¹ Validation | Loss: 0.2286 | Intent Acc: 0.9898 | Slot Acc: 0.9707\n","Epoch 3 finished | Avg Train Loss: 1.5637\n","ðŸ”¹ Validation | Loss: 0.2479 | Intent Acc: 0.9822 | Slot Acc: 0.9710\n","Epoch 4 finished | Avg Train Loss: 1.3523\n","ðŸ”¹ Validation | Loss: 0.2398 | Intent Acc: 0.9859 | Slot Acc: 0.9702\n","Epoch 5 finished | Avg Train Loss: 0.9289\n","ðŸ”¹ Validation | Loss: 0.2776 | Intent Acc: 0.9833 | Slot Acc: 0.9712\n","Epoch 6 finished | Avg Train Loss: 0.9119\n","ðŸ”¹ Validation | Loss: 0.2469 | Intent Acc: 0.9884 | Slot Acc: 0.9712\n","Epoch 7 finished | Avg Train Loss: 0.6840\n","ðŸ”¹ Validation | Loss: 0.2272 | Intent Acc: 0.9884 | Slot Acc: 0.9712\n","Epoch 8 finished | Avg Train Loss: 0.4094\n","ðŸ”¹ Validation | Loss: 0.2398 | Intent Acc: 0.9888 | Slot Acc: 0.9723\n","Epoch 9 finished | Avg Train Loss: 0.2843\n","ðŸ”¹ Validation | Loss: 0.2441 | Intent Acc: 0.9884 | Slot Acc: 0.9722\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","jb.to(device)\n","\n","epochs = 10\n","optimizer = torch.optim.Adam(lr=3e-5, params=jb.parameters())\n","\n","for epoch in range(epochs):\n","    epoch_loss = 0\n","    jb.train()\n","\n","    for idx, batch in enumerate(train_dataloader):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        slots = batch[\"slots\"].to(device)\n","        intent = batch[\"intent\"].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        total_loss_batch, intent_logits, slot_logits = jb(\n","            input_ids, attention_mask, slot_labels=slots, intent_labels=intent\n","        )\n","\n","        total_loss_batch.backward()\n","        optimizer.step()\n","\n","        epoch_loss += total_loss_batch.item()\n","\n","        # if idx % 20 == 0:\n","        #     print(f\"Epoch: {epoch} | Step: {idx} | Loss: {total_loss_batch.item()}\")\n","\n","    print(f\"Epoch {epoch} finished | Avg Train Loss: {epoch_loss:.4f}\")\n","\n","    jb.eval()\n","    val_loss = 0\n","    intent_correct, total_intent = 0, 0\n","    slot_correct, total_slot = 0, 0\n","    total_samples = 0\n","\n","    with torch.no_grad():\n","        for batch in val_dataloader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            slots = batch[\"slots\"].to(device)\n","            intent = batch[\"intent\"].to(device)\n","\n","            total_loss_batch, intent_logits, slot_logits = jb(\n","                input_ids, attention_mask, slot_labels=slots, intent_labels=intent\n","            )\n","\n","            val_loss += total_loss_batch.item() * input_ids.size(0)\n","            total_samples += input_ids.size(0)\n","\n","            intent_preds = intent_logits.argmax(dim=-1)\n","            intent_correct += (intent_preds == intent).sum().item()\n","            total_intent += intent.size(0)\n","\n","            valid_mask = slots != -100\n","            slot_preds = slot_logits.argmax(dim=-1)\n","            slot_correct += ((slot_preds == slots) & valid_mask).sum().item()\n","            total_slot += valid_mask.sum().item()\n","\n","    val_loss /= total_samples\n","    intent_acc = intent_correct / total_intent\n","    slot_acc = slot_correct / total_slot\n","\n","    print(f\"ðŸ”¹ Validation | Loss: {val_loss:.4f} | Intent Acc: {intent_acc:.4f} | Slot Acc: {slot_acc:.4f}\")"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"rOUg-v1hUUTo","executionInfo":{"status":"ok","timestamp":1739299148605,"user_tz":-60,"elapsed":32,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score\n","import torch\n","\n","def evaluate_model(jb, val_dataloader, device):\n","    jb.eval()\n","    intent_preds_all, intent_labels_all = [], []\n","    slot_preds_all, slot_labels_all = [], []\n","\n","    with torch.no_grad():\n","        for batch in val_dataloader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            slots = batch[\"slots\"].to(device)\n","            intent = batch[\"intent\"].to(device)\n","\n","            intent_preds, slot_preds = jb(input_ids, attention_mask)\n","\n","            # Intent Accuracy\n","            intent_preds = intent_preds.cpu().numpy()\n","            intent_labels = intent.cpu().numpy()\n","            intent_preds_all.extend(intent_preds)\n","            intent_labels_all.extend(intent_labels)\n","\n","            # Slot Predictions\n","            slot_preds = slot_preds.cpu().numpy()\n","            slot_labels = slots.cpu().numpy()\n","\n","            for pred, true in zip(slot_preds, slot_labels):\n","                valid_mask = true != -100\n","                slot_preds_all.append(pred[valid_mask].tolist())\n","                slot_labels_all.append(true[valid_mask].tolist())\n","\n","    # Intent Accuracy\n","    intent_acc = accuracy_score(intent_labels_all, intent_preds_all)\n","\n","    # Slot F1 (macro)\n","    slot_f1 = f1_score(\n","        [label for sublist in slot_labels_all for label in sublist],  # Flatten\n","        [pred for sublist in slot_preds_all for pred in sublist],  # Flatten\n","        average=\"macro\"\n","    )\n","\n","    correct_sentences = sum(\n","        (intent_preds_all[i] == intent_labels_all[i]) and\n","        (slot_preds_all[i] == slot_labels_all[i])\n","        for i in range(len(intent_preds_all))\n","    )\n","    sentence_acc = correct_sentences / len(intent_preds_all)\n","\n","    print(f\"ðŸ”¹ Validation Results:\")\n","    print(f\"Intent Accuracy: {intent_acc:.4f}\")\n","    print(f\"Slot F1 Score: {slot_f1:.4f}\")\n","    print(f\"Sentence-Level Semantic Frame Accuracy: {sentence_acc:.4f}\")\n","\n","    return intent_acc, slot_f1, sentence_acc"]},{"cell_type":"code","source":["intent_acc, slot_f1, sentence_acc = evaluate_model(jb, val_dataloader, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q00bTTQhQMlA","executionInfo":{"status":"ok","timestamp":1739299155007,"user_tz":-60,"elapsed":4594,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}},"outputId":"3f4dd956-a943-4761-b20a-df13c2dcaa2b"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ”¹ Validation Results:\n","Intent Accuracy: 0.9884\n","Slot F1 Score: 0.9304\n","Sentence-Level Semantic Frame Accuracy: 0.8894\n"]}]},{"cell_type":"code","source":["!pip install huggingface_hub\n","from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["9b5b607aa7524bfc8461a8d6fa9ef11b","b94d8001f7574600ae199b5b89e70d5f","f873500c660e4e48b4ab411496de75c4","3dc68ffbe5ab487989806ea1ae34b755","6c6862fdb00542dbbff0b1d11adc7c1f","8217c9d23be64ad3b08eeb2eba518206","08fb1eec840a48508c44b5fb144913d8","b09031a6ce9a42e6b6afca3320356b5b","07d12799c8654494845968e2e27c0679","b5afc0c6c29e41849f294b66707ee493","83c179fedb31447f8808cf0390f1fb90","6efb101143e34910a95b32915e0c7114","4142078c20dd4daab0a4d07c78262134","84df7d1574124ccaa6be14151ec705e1","db5849ca06d04677923d3928dd5db952","342bbc107581496a88ff8b89c6c2b284","bb6ba3781db14d0390fc29534ee5181e","ee13d28e086a455eb86f86c6f8826cf5","218e1d49e6b8499e9ed060c95515838d","1a0e1b72c71d4cb5852682af46411328"]},"id":"gZo7Yzp7RHxR","executionInfo":{"status":"ok","timestamp":1739300343949,"user_tz":-60,"elapsed":2223,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}},"outputId":"72a174a6-fb19-45d9-b294-1ce157483b80"},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b5b607aa7524bfc8461a8d6fa9ef11b"}},"metadata":{}}]},{"cell_type":"code","source":["!apt install git\n","!git config --global user.name \"antonItachi\"\n","!git config --global user.email \"mrkrasnyuk21@gmail.com\""],"metadata":{"id":"SfEWwaXQZRs3","executionInfo":{"status":"ok","timestamp":1739300642646,"user_tz":-60,"elapsed":2521,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/antonItachi/intent-slot-classification.git"],"metadata":{"id":"wdIIwOT_ZZOk","executionInfo":{"status":"ok","timestamp":1739300660080,"user_tz":-60,"elapsed":905,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/Colab\\Notebooks/bert.ipynb /content/intent-slot-classification"],"metadata":{"id":"6g46OZ5RZd4Q","executionInfo":{"status":"ok","timestamp":1739300943090,"user_tz":-60,"elapsed":119,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["!cd intent-slot-classification && git add ."],"metadata":{"id":"nkhyZznFZoPs","executionInfo":{"status":"ok","timestamp":1739300947001,"user_tz":-60,"elapsed":109,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["!cd intent-slot-classification && git commit -m \"Added NLU model code\"\n","!cd intent-slot-classification && git branch -M main\n","!cd intent-slot-classification && git remote add origin https://github.com/antonItachi/intent-slot-classification.git\n","!cd intent-slot-classification && git push -u origin main"],"metadata":{"id":"sSni5hqFZr6k","executionInfo":{"status":"ok","timestamp":1739300947749,"user_tz":-60,"elapsed":713,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"aGDqga3PaBJL","executionInfo":{"status":"ok","timestamp":1739300952498,"user_tz":-60,"elapsed":2194,"user":{"displayName":"Anton Krasniuk","userId":"12003612234082770579"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HF3YufFIZ1eA"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMjfiqizOvQQZD7fnjMNz7Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9b5b607aa7524bfc8461a8d6fa9ef11b":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_08fb1eec840a48508c44b5fb144913d8"}},"b94d8001f7574600ae199b5b89e70d5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09031a6ce9a42e6b6afca3320356b5b","placeholder":"â€‹","style":"IPY_MODEL_07d12799c8654494845968e2e27c0679","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"f873500c660e4e48b4ab411496de75c4":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_b5afc0c6c29e41849f294b66707ee493","placeholder":"â€‹","style":"IPY_MODEL_83c179fedb31447f8808cf0390f1fb90","value":""}},"3dc68ffbe5ab487989806ea1ae34b755":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_6efb101143e34910a95b32915e0c7114","style":"IPY_MODEL_4142078c20dd4daab0a4d07c78262134","value":false}},"6c6862fdb00542dbbff0b1d11adc7c1f":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_84df7d1574124ccaa6be14151ec705e1","style":"IPY_MODEL_db5849ca06d04677923d3928dd5db952","tooltip":""}},"8217c9d23be64ad3b08eeb2eba518206":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_342bbc107581496a88ff8b89c6c2b284","placeholder":"â€‹","style":"IPY_MODEL_bb6ba3781db14d0390fc29534ee5181e","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"08fb1eec840a48508c44b5fb144913d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"b09031a6ce9a42e6b6afca3320356b5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d12799c8654494845968e2e27c0679":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5afc0c6c29e41849f294b66707ee493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83c179fedb31447f8808cf0390f1fb90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6efb101143e34910a95b32915e0c7114":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4142078c20dd4daab0a4d07c78262134":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84df7d1574124ccaa6be14151ec705e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db5849ca06d04677923d3928dd5db952":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"342bbc107581496a88ff8b89c6c2b284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb6ba3781db14d0390fc29534ee5181e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee13d28e086a455eb86f86c6f8826cf5":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_218e1d49e6b8499e9ed060c95515838d","placeholder":"â€‹","style":"IPY_MODEL_1a0e1b72c71d4cb5852682af46411328","value":"Connecting..."}},"218e1d49e6b8499e9ed060c95515838d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a0e1b72c71d4cb5852682af46411328":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}